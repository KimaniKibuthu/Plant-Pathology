{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Plant Pathology.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimaniKibuthu/Plant-Pathology/blob/main/Plant_Pathology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmtV332n0sMZ"
      },
      "source": [
        "# Plant Pathology\n",
        "\n",
        "The main objective of the competition is to develop machine learning-based models to accurately classify a given leaf image from the test dataset to a particular disease category, and to identify an individual disease from multiple disease symptoms on a single leaf image. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w-Agq473usq"
      },
      "source": [
        "# Libraries and Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnQskPTWGDrt"
      },
      "source": [
        "# %tensorflow_version 2.x\n",
        "# import tensorflow as tf\n",
        "# print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "# try:\n",
        "#   tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "#   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "# except ValueError:\n",
        "#   raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "# tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy6fHksL6t5k"
      },
      "source": [
        "!pip uninstall kaggle\n",
        "!pip install --upgrade kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__lI2AaYz0B-"
      },
      "source": [
        "# General libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Modelling\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.applications import ResNet101V2\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MtZPKKw5-kl"
      },
      "source": [
        "# Variables\n",
        "TARGET_SIZE = 224\n",
        "TEST_SIZE = 0.5\n",
        "BATCH_SIZE = 64\n",
        "RANDOM_STATE = 42\n",
        "EPOCHS = 25\n",
        "LR = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2w2ElsD5c47"
      },
      "source": [
        "# Data Obtainance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSU0FlLp5beg"
      },
      "source": [
        "# Load credentials\n",
        "def credentials(name, token_id):\n",
        "   # Setup the username and ID\n",
        "  os.environ[\"KAGGLE_USERNAME\"] = name\n",
        "  os.environ[\"KAGGLE_KEY\"] = token_id\n",
        "\n",
        "  print('Done!')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6afCKt_n6PlP"
      },
      "source": [
        "# Get data\n",
        "\n",
        "credentials('kimanikibuthu', 'f85c0bb5d43058fddcce7902e1325677')\n",
        "\n",
        "!kaggle competitions download -c plant-pathology-2021-fgvc8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52M5chuZ6diJ"
      },
      "source": [
        "!unzip /content/plant-pathology-2021-fgvc8.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPTkP9u88jvN"
      },
      "source": [
        "# Load into variables\n",
        "train = pd.read_csv('/content/train.csv')\n",
        "submission = pd.read_csv('/content/sample_submission.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B0--BUK93RD"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dFrhbEx-Aao"
      },
      "source": [
        "**General Exploration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT0DzHvy91uj"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWKn5wCl-Li1"
      },
      "source": [
        "# Info\n",
        "train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0E06L-o-UG-"
      },
      "source": [
        "**Explore Labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MMskedn-RXY"
      },
      "source": [
        "# Value_counts\n",
        "train['labels'].value_counts(normalize=True)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf_ERY00-cps"
      },
      "source": [
        "# Visualize them\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.countplot(y='labels', \n",
        "              data=train,\n",
        "              palette='husl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfvmkj3c_U9X"
      },
      "source": [
        "The data is imbalanced, hence we will need to deal with it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmTu66I__KyB"
      },
      "source": [
        "# Label encode the  labels\n",
        "\n",
        "map = {}\n",
        "for key, value in dict(enumerate(train['labels'].unique())).items():\n",
        "  map[value] = str(key)\n",
        "\n",
        "train['labels'] = train['labels'].replace(map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4Z1N3VhEvcq"
      },
      "source": [
        "**Visualize Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7GzRBQgBug7"
      },
      "source": [
        "\n",
        "def show_images(label, data):\n",
        "    # Get images \n",
        "    df = data.loc[data['labels'] == label]\n",
        "    images = df['image'].values\n",
        "\n",
        "    # Extract 16 random images from it\n",
        "    random_images = [np.random.choice(images) for i in range(9)]\n",
        "\n",
        "    # Adjust the size of your images\n",
        "    plt.figure(figsize=(16,12))\n",
        "\n",
        "    # Iterate and plot random images\n",
        "    for i in range(9):\n",
        "        plt.subplot(3,3, i + 1)\n",
        "        img = plt.imread(os.path.join('/content/train_images', random_images[i]))\n",
        "        \n",
        "        try:\n",
        "          plt.imshow(img, cmap='gray')\n",
        "          plt.axis('off')\n",
        "        except FileNotFoundError:\n",
        "          pass\n",
        "\n",
        "    # Adjust subplot parameters to give specified padding\n",
        "    plt.tight_layout() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrhDkldzL66N"
      },
      "source": [
        "map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORDtYWObLPk3"
      },
      "source": [
        "***Healthy(0)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nqN1OC_LN1L"
      },
      "source": [
        "show_images('0', train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-Hd6EkYMrb9"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5V7EIiAMxM8"
      },
      "source": [
        "***scab frog_eye_leaf_spot complex (1)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqVPrkZQMQbl"
      },
      "source": [
        "show_images('1', train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mMu77LfPePo"
      },
      "source": [
        "***scab (2)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcGUDDgSOno-"
      },
      "source": [
        "show_images('2', train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJGFh6ubP7ui"
      },
      "source": [
        "***complex (3)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKHBBl1DPrk6"
      },
      "source": [
        "show_images('3', train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhkECF1_QJk9"
      },
      "source": [
        "***rust (4)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ9u30GQQFXf"
      },
      "source": [
        "show_images('4', train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By56lUAEt1wr"
      },
      "source": [
        "***frog_eye_leaf_spot (5)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQGJ_kRlQVim"
      },
      "source": [
        "show_images('5', train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpMc1QbmuC5-"
      },
      "source": [
        "***powdery_mildew (6)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq2ramLcuSo5"
      },
      "source": [
        "show_images('6', train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFqsLQ8DugJX"
      },
      "source": [
        "***scab frog_eye_leaf_spot (7)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9BbeJUlu4oc"
      },
      "source": [
        "show_images('7', train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjecF2W3u5HU"
      },
      "source": [
        "***frog_eye_leaf_spot complex (8)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58mernHZu6xS"
      },
      "source": [
        "show_images('8', train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTPjtH6hu7LL"
      },
      "source": [
        "***rust frog_eye_leaf_spot (9)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yziwjfiVu8pJ"
      },
      "source": [
        "show_images('9', train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARDO_RcGu9JU"
      },
      "source": [
        "***powdery_mildew complex (10)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiG_AEqDu-gl"
      },
      "source": [
        "show_images('10', train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKKshkeMu_8Y"
      },
      "source": [
        "***rust complex (11)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBwRnKrvvIlo"
      },
      "source": [
        "show_images('11', train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WlWykER5UYV"
      },
      "source": [
        "# Split data\n",
        "\n",
        "train_set, val_set = train_test_split(train,\n",
        "                                      test_size=0.1,\n",
        "                                      random_state=RANDOM_STATE,\n",
        "                                      stratify=train['labels'])\n",
        "\n",
        "train_set = train_set.reset_index(drop=True)\n",
        "val_set = val_set.reset_index(drop=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvI4CtrhwBWd"
      },
      "source": [
        "**Loading Into Generators**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndi8xkCTwEex"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    #rescale=1/255,\n",
        "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input\n",
        "    )\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    #rescale=1/255,\n",
        "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyH92Fcr5CdK"
      },
      "source": [
        "train_flow = train_datagen.flow_from_dataframe(\n",
        "    train_set,\n",
        "    '/content/train_images',\n",
        "    x_col = 'image',\n",
        "    y_col = 'labels',\n",
        "    target_size = (TARGET_SIZE, TARGET_SIZE),\n",
        "    class_mode = 'categorical',\n",
        "    batch_size = BATCH_SIZE\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "val_flow = val_datagen.flow_from_dataframe(\n",
        "    val_set,\n",
        "    '/content/train_images',\n",
        "    x_col = 'image',\n",
        "    y_col = 'labels',\n",
        "    target_size = (TARGET_SIZE, TARGET_SIZE),\n",
        "    class_mode = 'categorical',\n",
        "    batch_size = BATCH_SIZE\n",
        "\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0pqFBu79MoC"
      },
      "source": [
        "# Visualize an image\n",
        "x_batch, y_batch = next(train_flow)\n",
        "for i in range (0,6):\n",
        "    image = x_batch[i]\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PYtLCOC_OOm"
      },
      "source": [
        "NUM_CLASSES = len(np.unique(train_flow.classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mGbLjcn-WOS"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKOFNKOl976H"
      },
      "source": [
        "def create_model():\n",
        "  global NUM_CLASSES\n",
        "  # Build model\n",
        "  resnet = ResNet101V2(include_top=False, \n",
        "                          input_shape=(TARGET_SIZE, TARGET_SIZE, 3),\n",
        "                          weights='imagenet')\n",
        "  \n",
        "  for layer in resnet.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "  model = Sequential([\n",
        "                      resnet,\n",
        "                      GlobalAveragePooling2D(),\n",
        "                      # Flatten(),\n",
        "                      # Dense(256, activation = 'relu', \n",
        "                      #     bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, \n",
        "                      #                                                 l2=0.001)),\n",
        "                      # Dropout(0.5),\n",
        "                      # Dense(32, activation = 'relu',\n",
        "                      #     bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01,\n",
        "                      #                                                 l2=0.001)),\n",
        "                      # Dropout(0.5),\n",
        "                      Dense(NUM_CLASSES, activation = 'softmax')\n",
        "  ])\n",
        "\n",
        "  # Instantiate learning rate and optimizer\n",
        "  loss = tf.keras.losses.CategoricalCrossentropy(from_logits = False,\n",
        "                                                   label_smoothing=0.01,\n",
        "                                                   name='categorical_crossentropy' )\n",
        "\n",
        "  adam = tf.keras.optimizers.Adam(LR)\n",
        "\n",
        "  auc = tf.keras.metrics.AUC(\n",
        "    num_thresholds=200, curve='ROC',\n",
        "    summation_method='interpolation', name=None, dtype=None,\n",
        "    thresholds=None, multi_label=False, num_labels=None, label_weights=None,\n",
        "    from_logits=False)\n",
        "\n",
        "  # Compile model\n",
        "  model.compile(loss = loss,\n",
        "                optimizer = adam,\n",
        "                metrics = ['categorical_accuracy', auc])\n",
        "  \n",
        "  return model\n",
        "  \n",
        "# with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "#   model = create_model()\n",
        "model = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaMTZY5o-yyN"
      },
      "source": [
        "def model_fitter(model):\n",
        "\n",
        "  # instantiate callbacks\n",
        "  \n",
        "  early_stopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                 patience=5)\n",
        "\n",
        "  # reduce learning rate\n",
        "  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                                  factor = 0.1,\n",
        "                                  patience = 2,\n",
        "                                  min_lr = 1e-6,\n",
        "                                  mode = 'min',\n",
        "                                  verbose = 1)\n",
        "\n",
        "  callbacks = [early_stopper, reduce_lr]\n",
        "\n",
        "  # Train model\n",
        "  history = model.fit(train_flow,\n",
        "                    epochs=EPOCHS,\n",
        "                    steps_per_epoch=int(np.ceil(len(train_set)/BATCH_SIZE)),\n",
        "                    callbacks=callbacks,\n",
        "                    validation_data=val_flow,\n",
        "                    validation_steps=int(np.ceil(len(val_set)/BATCH_SIZE))\n",
        "                    )\n",
        "  \n",
        "  return history, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPXE0dLS_L_f"
      },
      "source": [
        "# Fit model\n",
        "history, model = model_fitter(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSV2qGbd_0PM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}